{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc8c8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, True, True]\n",
      "[True, True, True, True]\n",
      "[True, True, False, True, False]\n",
      "[False, False, True, True]\n",
      "[True, False, True, True, True, False]\n",
      "[True, False, True, True]\n",
      "[False, False, True, True, False, True, False]\n",
      "[True, False, True, True, True, True, True]\n",
      "[False, True, True, True, False, True, True, True]\n",
      "[False, False, True, True, True, False]\n",
      "[False, False]\n",
      "[False, True]\n",
      "[True]\n",
      "[False, False, False]\n",
      "[True, True]\n",
      "[False, False, True]\n",
      "[False, True]\n",
      "[True, True, False]\n",
      "[True, False]\n",
      "[True, False]\n",
      "[True, False, True]\n",
      "[True, True, True]\n",
      "[False, False]\n",
      "\n",
      "\n",
      "testing own data...\n",
      "\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from typing import NamedTuple\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "\n",
    "\n",
    "def data_entropy(labels):\n",
    "    print(labels)\n",
    "    # Compute the class probabilities\n",
    "    # Counter(labels).values() stores the value (False/Negative) as dict key and the count as dict value\n",
    "    total_count = len(labels)\n",
    "    class_probabilities = []\n",
    "    for count in Counter(labels).values():\n",
    "        class_probabilities.append(count / total_count)\n",
    "\n",
    "    # Given a list of class probabilities, compute the entropy\n",
    "    entropy = sum(-p * math.log(p, 2) for p in class_probabilities if p > 0)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def partition_entropy(subsets):\n",
    "    # Returns the entropy from this partition of data into subsets\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)\n",
    "\n",
    "\n",
    "def partition_by(inputs, attribute):\n",
    "    # Partitions the inputs into two dictionary lists,\n",
    "    # one set containing the individuals with the attribute as False\n",
    "    # and one containing the individuals with the attribute as True\n",
    "    partitions = defaultdict(list)\n",
    "    # For each Individual in out inputs list\n",
    "    for input in inputs:\n",
    "        # get the value of the attribute for this Individual\n",
    "        attribute_value = getattr(input, attribute)\n",
    "        # Append the input to the partitions list based on the attribute value\n",
    "        partitions[attribute_value].append(input)\n",
    "\n",
    "    # The key of this partitions dict is True or False,\n",
    "    # i.e. the True set contains all individuals whos attribute is True\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def partition_entropy_by(inputs, attribute, label_attribute):\n",
    "    # Calculates the entropy of a given partition\n",
    "    # First, partition the inputs by the attribute we want to calculate entropy for\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "\n",
    "    labels = []\n",
    "    # partitions.values() gets the set of individuals corresponding to the True/False dict keys\n",
    "    # For each partition in the partitions dict,\n",
    "    for i, partition in enumerate(partitions.values()):\n",
    "        labels.append([])\n",
    "        # For each Individual in this partition,\n",
    "        for input in partition:\n",
    "            # append the value of label_attribute for this Individual to the labels list at the the same partition index\n",
    "            labels[i].append(getattr(input, label_attribute))\n",
    "\n",
    "    # Return the entropy value for the partition\n",
    "    return partition_entropy(labels)\n",
    "\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    # A Leaf predicts a single value, i.e. Hire or Not Hire\n",
    "    value: None\n",
    "\n",
    "\n",
    "class Split(NamedTuple):\n",
    "    # A Split contains an attribute to split on,\n",
    "    # the subtrees for specific values of that attrivute,\n",
    "    # and a default value if we see and unknown value\n",
    "    attribute: str\n",
    "    subtrees: dict\n",
    "    default_value: None\n",
    "\n",
    "\n",
    "def classify(tree, input):\n",
    "    # Classify the input using the given decision tree\n",
    "\n",
    "    # If this is a leaf node, return its value loop is done\n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.value\n",
    "\n",
    "    # Otherwise this tree consists of an attribute to split on\n",
    "    # and a dictionary whose keys are values of that attribute\n",
    "    # and whose values are subtrees to consider next\n",
    "    subtree_key = getattr(input, tree.attribute)\n",
    "\n",
    "    if subtree_key not in tree.subtrees:   # If no subtree for key,\n",
    "        return tree.default_value          # return the default value.\n",
    "\n",
    "    subtree = tree.subtrees[subtree_key]   # Choose the appropriate subtree\n",
    "    return classify(subtree, input)        # and use it to classify the input.\n",
    "\n",
    "\n",
    "def build_tree(inputs, split_attributes, target_attribute):\n",
    "    # Count target labels, these are stores in label_counts under the value key\n",
    "    # (i.e. True or False)\n",
    "    label_counts = Counter(getattr(input, target_attribute)\n",
    "                           for input in inputs)\n",
    "\n",
    "    # Find most common label\n",
    "    # most_common(number of values to return; i.e. most common 1 or 3 etc.)\n",
    "    most_common_label = label_counts.most_common(1)[0][0]\n",
    "\n",
    "    # If there is only one label in label_counts,\n",
    "    # this ends the loop and we return the prediction\n",
    "    if len(label_counts) == 1:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # If there are no more splits available in our decision tree,\n",
    "    # We return the prediction for the majority label\n",
    "    if not split_attributes:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # Otherwise we split by the best attribute\n",
    "\n",
    "    def split_entropy(attribute):\n",
    "        # Helper function for finding the best attribute\n",
    "        return partition_entropy_by(inputs, attribute, target_attribute)\n",
    "\n",
    "    # Find the best_attribute to split by; i.e. the attribute with the lowest entropy\n",
    "    # This \"min\" function will return the minimum attribute in the split_attributes list\n",
    "    # based on the return return value of split_entropy for each attribute.\n",
    "    best_attribute = min(split_attributes, key=split_entropy)\n",
    "\n",
    "    # Partition based on the best_attribute\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    # Create a new list of attributes to pass through in the recursive call\n",
    "    # (removing the best_attribute we just split on)\n",
    "    new_attributes = [a for a in split_attributes if a != best_attribute]\n",
    "\n",
    "    # Create the subtrees for this split\n",
    "    # Subtrees are stored using the attribute_value as the key in the subtrees dict\n",
    "    # The subtree stored under each key is created by recursivelly calling this same function,\n",
    "    # passing the subset of input values stored in each partition of our partitions set from above.\n",
    "    subtrees = {attribute_value: build_tree(subset, new_attributes, target_attribute)\n",
    "                for attribute_value, subset in partitions.items()}\n",
    "\n",
    "    # For each recursive call of this function, we continue down the tree until we hit a leaf node\n",
    "    # at which point one of the previous return conditions are met and a leaf prediciton is returned.\n",
    "    # Once the recursive call to populate subtrees above is completed, we return the parent split of these subtrees.\n",
    "    return Split(best_attribute, subtrees, default_value=most_common_label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Named tuples assign a name to each position in a tuple.\n",
    "    # They allow the ability to access fields by this name instead of position index.\n",
    "    class Individual(NamedTuple):\n",
    "        outlook: str\n",
    "        temp: str\n",
    "        humidity: str\n",
    "        wind: str\n",
    "        did_run: bool = None\n",
    "        # We allow \"None\" here, for when we are predicting this based on the other inputs.\n",
    "\n",
    "    # Inputs using the Individual class for easy referencing\n",
    "    #                    outlook     temp    humidity  wind      did_run\n",
    "    inputs = [Individual('Sunny',    'Hot',  'High',   'Weak',   False),\n",
    "              Individual('Sunny',    'Hot',  'High',   'Strong', False),\n",
    "              Individual('Overcast', 'Hot',  'High',   'Weak',   True),\n",
    "              Individual('Rain',     'Mild', 'High',   'Weak',   True),\n",
    "              Individual('Rain',     'Cool', 'Normal', 'Weak',   True),\n",
    "              Individual('Rain',     'Cool', 'Normal', 'Strong', False),\n",
    "              Individual('Overcast', 'Cool', 'Normal', 'Strong', True),\n",
    "              Individual('Sunny',    'Mild', 'High',   'Weak',   False),\n",
    "              Individual('Sunny',    'Cool', 'Normal', 'Weak',   True),\n",
    "              Individual('Rain',     'Mild', 'Normal', 'Weak',   True),\n",
    "              Individual('Sunny',    'Mild', 'Normal', 'Strong', True),\n",
    "              Individual('Overcast', 'Mild', 'High',   'Strong', True),\n",
    "              Individual('Overcast', 'Hot',  'Normal', 'Weak',   True),\n",
    "              Individual('Rain',     'Mild', 'High',   'Strong', False)\n",
    "              ]\n",
    "\n",
    "    # Generate the decision tree based on our inputs data.\n",
    "    # We pass did_run as our target, this is what we want to predict.\n",
    "    attributes = ['outlook', 'temp', 'humidity', 'wind']\n",
    "    target_attribute = 'did_run'\n",
    "    tree = build_tree(inputs, attributes, target_attribute)\n",
    "\n",
    "    \n",
    "    print(\"\\n\\ntesting own data...\\n\")\n",
    "    # Test the tree on new data.\n",
    "    # This should predict True,\n",
    "    print(classify(tree, Individual(\"Sunny\", \"Mild\", \"Normal\", \"Weak\")))\n",
    "\n",
    "    # and this should predict False.\n",
    "    print(classify(tree, Individual(\"Rain\", \"Cold\", \"High\", \"Strong\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef8256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
